# AI Daily Lead Acquisition Workflow

**File**: `ai-daily-lead-acquisition.json`  
**Replaces**: 5 separate workflows  
**Architecture**: One AI agent orchestrates everything

---

## ğŸ¯ **What This Replaces**

| Old System (5 Workflows) | New AI System (1 Workflow) |
|-------------------------|---------------------------|
| PropertyRadar Pull Worker | âœ… Phase 1: Pull loop |
| Enrichment Waterfall | âœ… Phase 1: Inline enrichment |
| Q2H Backfill Checker | âŒ Not needed (loop ensures target) |
| EOD Backfill | âŒ Not needed (loop ensures target) |
| Campaign Feeder | âœ… Phase 2: Campaign upload |

---

## ğŸ”§ **How It Works**

### **Daily at 6am**:
```
1. Fetch active brokers from Supabase
2. For each broker (loop):
   â”‚
   â””â”€ ğŸ¤– AI Controller runs:
       â”‚
       â”œâ”€ PHASE 1: PULL & ENRICH (loop until target)
       â”‚   1. Count enriched so far
       â”‚   2. Pull batch from PropertyRadar
       â”‚   3. Filter duplicates
       â”‚   4. Buy properties
       â”‚   5. Enrich with /persons (PropertyRadar)
       â”‚   6. Fallback to BatchData if quality < 70
       â”‚   7. Merge best email/phone from both
       â”‚   8. Insert to Supabase
       â”‚   9. Update offset
       â”‚   10. Loop if < target, else Phase 2
       â”‚
       â””â”€ PHASE 2: CAMPAIGN UPLOAD
           1. Get all enriched leads from today
           2. Assign archetype (high_equity/cash_unlocked/no_payment)
           3. Upload to Instantly (3 campaigns)
           4. Update leads: campaign_status='active'
           5. Done!
```

---

## ğŸ¯ **Dynamic Capacity**

Each broker has their own `daily_lead_capacity` in Supabase:
- Broker A: 50 leads/day
- Broker B: 250 leads/day
- Broker C: 500 leads/day

**AI adapts**:
- Small quotas (â‰¤100): Pull 20 per batch
- Medium quotas (100-300): Pull 30 per batch
- Large quotas (>300): Pull 50 per batch
- Batch size auto-adjusts based on enrichment rate

---

## ğŸ› ï¸ **Tools the AI Uses**

### **ğŸ’¾ Supabase MCP** (29 tools):
- `execute_sql` - All database operations
- Count enriched, filter dupes, insert leads, update offset, get campaigns

### **ğŸ˜ï¸ PropertyRadar API** (HTTP Request Tool):
- GET `/lists/{id}/items` - Pull RadarIDs
- POST `/properties` - Buy property data
- GET `/properties/{id}/persons` - Enrich contacts

### **ğŸ“Š BatchData API** (HTTP Request Tool):
- POST `/api/v1/property/skip-trace` - Fallback enrichment

### **ğŸ“§ Instantly API** (HTTP Request Tool):
- POST `/api/v1/lead/add` - Upload to campaigns

---

## ğŸ¯ **Enrichment Strategy**

For each property:
1. **Try PropertyRadar /persons first** ($0.75)
   - Extract emails/phones
   - Score quality (0-100)
   
2. **If quality < 70** â†’ **Fallback to BatchData** ($0.75)
   - Get additional contacts
   
3. **Merge best** from both sources
   - Highest-scored email
   - Highest-scored phone
   - Combined quality score

4. **Only count as "enriched"** if email OR phone exists

---

## ğŸ“Š **Safety Limits**

- **Max pulls**: 2x daily capacity (prevents runaway)
- **Max iterations**: 30
- **Max runtime**: 60 minutes
- **Min enrichment rate**: 50% (stops if quality tanks)

**Example**: Broker with 250 capacity
- Will pull max 500 properties
- Stops if enrichment rate drops below 50%
- Guarantees no runaway costs

---

## âœ… **Success Criteria**

- âœ… Enriched count >= daily_capacity (within 5%)
- âœ… All enriched leads uploaded to Instantly
- âœ… Broker offset updated correctly
- âœ… Campaign archetypes assigned
- âœ… Complete in < 60 minutes

---

## ğŸ¨ **Workflow Nodes** (10 total):

1. **Daily Trigger (6am PT)** - Schedule trigger
2. **Fetch Active Brokers** - Supabase query
3. **Loop Over Brokers** - Process each broker
4. **Prepare Broker Context** - Extract broker config
5. **ğŸ¤– AI Controller** - The orchestrator (does everything!)
6. **Claude Sonnet 4.5** - LLM for AI agent
7. **ğŸ’¾ Supabase MCP** - Database operations
8. **ğŸ˜ï¸ PropertyRadar API** - Property data
9. **ğŸ“Š BatchData API** - Enrichment fallback
10. **ğŸ“§ Instantly API** - Campaign upload
11. **ğŸ“Š Parse Results** - Logging
12. **Loop back** - Next broker

---

## ğŸ’° **Cost Efficiency**

**Built-in optimization**:
- Stops immediately when target reached
- Skips duplicate properties (saves $0.75 each)
- Only uses BatchData when needed (not every property)
- Dynamic batch sizing reduces API calls

**Example** (250 capacity, 82% enrichment rate):
- Pull: ~305 properties ($228.75)
- Enrich PR: 305 properties ($228.75)
- Enrich BD fallback: ~55 properties ($41.25)
- **Total**: ~$499/broker/day

vs old system with backfills: ~$550-600/day

---

## ğŸš€ **Why This is Revolutionary**

### **Old System**:
- 5 separate workflows
- Hardcoded logic
- Backfills needed
- Manual capacity checking
- Brittle error handling

### **New AI System**:
- 1 workflow
- AI decides everything
- Self-correcting loop
- Dynamic capacity
- Intelligent error recovery

**One AI agent replaces 500+ lines of deterministic code!**

---

## ğŸ“‹ **Setup Requirements**

### **Configure MCP Endpoints**:
- Supabase MCP (need endpoint URL)
- Or keep as HTTP Request Tools for PropertyRadar/BatchData/Instantly

### **Credentials Needed**:
- âœ… Supabase (you have)
- âœ… PropertyRadar (you have)
- âœ… OpenRouter (you have)
- â³ BatchData API key
- âœ… Instantly (you have)

### **Database Setup**:
- âœ… Brokers table with `daily_lead_capacity`, `propertyradar_list_id`, `propertyradar_offset`
- âœ… Leads table ready
- âœ… Campaigns table with archetype mappings

---

## ğŸ“ **Next Steps**

1. Import `ai-daily-lead-acquisition.json`
2. Configure Supabase MCP endpoint (or it will use SQL via tools)
3. Test with one broker first
4. Monitor AI decisions in logs
5. Adjust prompt if needed
6. Deploy to production!

---

**This is enterprise-grade agentic AI architecture!** ğŸ†

