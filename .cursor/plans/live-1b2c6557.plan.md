<!-- 1762da9a-072f-4883-92fd-fa2483456560 fd9b7756-68ce-4abc-8d00-9a804d71c360 -->
# LiveKit AI Templates - Complete Implementation

## 1. Database Schema

### Migration: `database/migrations/20250109_ai_templates.sql`

```sql
-- AI Templates Table
CREATE TABLE ai_templates (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  broker_id UUID REFERENCES brokers(id) ON DELETE CASCADE,
  name TEXT NOT NULL,
  description TEXT,
  
  -- STT Configuration
  -- eden_ai is aggregator for: Deepgram, AssemblyAI, Google, Whisper, etc.
  -- openai_realtime is bundled (STT included in realtime model)
  stt_provider TEXT NOT NULL CHECK (stt_provider IN ('eden_ai', 'openai_realtime')),
  stt_model TEXT NOT NULL, -- e.g., 'deepgram-nova-2', 'assemblyai-best', 'google-latest'
  stt_language TEXT DEFAULT 'en-US',
  
  -- TTS Configuration  
  -- eden_ai is aggregator for: ElevenLabs, PlayHT, Google, Amazon Polly, etc.
  -- openai_realtime is bundled (TTS included in realtime model)
  tts_provider TEXT NOT NULL CHECK (tts_provider IN ('eden_ai', 'openai_realtime')),
  tts_model TEXT NOT NULL, -- e.g., 'elevenlabs-multilingual-v2', 'playht-2.0-turbo', 'google-neural2'
  tts_voice_id TEXT NOT NULL,
  tts_speed NUMERIC DEFAULT 1.0 CHECK (tts_speed BETWEEN 0.5 AND 2.0),
  tts_stability NUMERIC DEFAULT 0.5 CHECK (tts_stability BETWEEN 0 AND 1),
  
  -- LLM Configuration
  -- openrouter is aggregator for: OpenAI, Anthropic, Meta, Google, Mistral, etc.
  -- openai_realtime is direct (only GPT-4o-realtime, bypasses aggregators)
  llm_provider TEXT NOT NULL CHECK (llm_provider IN ('openrouter', 'openai_realtime')),
  llm_model TEXT NOT NULL, -- e.g., 'openai/gpt-4o', 'anthropic/claude-3.5-sonnet', 'gpt-4o-realtime-preview'
  llm_temperature NUMERIC DEFAULT 0.7 CHECK (llm_temperature BETWEEN 0 AND 2),
  llm_max_tokens INTEGER DEFAULT 4096 CHECK (llm_max_tokens > 0),
  llm_top_p NUMERIC DEFAULT 1.0 CHECK (llm_top_p BETWEEN 0 AND 1),
  llm_frequency_penalty NUMERIC DEFAULT 0.0 CHECK (llm_frequency_penalty BETWEEN -2 AND 2),
  llm_presence_penalty NUMERIC DEFAULT 0.0 CHECK (llm_presence_penalty BETWEEN -2 AND 2),
  
  -- VAD (Voice Activity Detection) Configuration
  vad_enabled BOOLEAN DEFAULT TRUE,
  vad_threshold NUMERIC DEFAULT 0.5 CHECK (vad_threshold BETWEEN 0 AND 1),
  vad_prefix_padding_ms INTEGER DEFAULT 300 CHECK (vad_prefix_padding_ms >= 0),
  vad_silence_duration_ms INTEGER DEFAULT 500 CHECK (vad_silence_duration_ms >= 0),
  
  -- Turn Detection (for realtime models)
  turn_detection_type TEXT DEFAULT 'server_vad' CHECK (turn_detection_type IN ('server_vad', 'none')),
  
  -- Audio Configuration
  audio_input_transcription BOOLEAN DEFAULT TRUE,
  audio_sample_rate INTEGER DEFAULT 24000 CHECK (audio_sample_rate IN (16000, 24000, 48000)),
  
  -- Cost tracking (estimated $/minute)
  estimated_cost_per_minute NUMERIC,
  
  -- System presets
  is_system_default BOOLEAN DEFAULT FALSE,
  is_preset BOOLEAN DEFAULT FALSE,
  
  -- Metadata
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  created_by UUID REFERENCES auth.users(id),
  
  -- Constraints
  CONSTRAINT valid_broker_template CHECK (
    (is_system_default = TRUE AND broker_id IS NULL) OR
    (is_system_default = FALSE AND broker_id IS NOT NULL)
  )
);

-- Indexes for performance
CREATE INDEX idx_ai_templates_broker_id ON ai_templates(broker_id);
CREATE INDEX idx_ai_templates_system_default ON ai_templates(is_system_default) WHERE is_system_default = TRUE;
CREATE INDEX idx_ai_templates_preset ON ai_templates(is_preset) WHERE is_preset = TRUE;

-- Updated_at trigger
CREATE TRIGGER set_ai_templates_updated_at
  BEFORE UPDATE ON ai_templates
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();

-- Usage count view (materialized for performance)
CREATE MATERIALIZED VIEW ai_template_usage AS
SELECT 
  t.id AS template_id,
  t.name,
  COUNT(p.id) AS phone_count,
  COUNT(DISTINCT p.broker_id) AS broker_count
FROM ai_templates t
LEFT JOIN signalwire_phone_numbers p ON p.assigned_ai_template_id = t.id
GROUP BY t.id, t.name;

CREATE UNIQUE INDEX idx_ai_template_usage_template_id ON ai_template_usage(template_id);

-- Refresh function for usage stats
CREATE OR REPLACE FUNCTION refresh_ai_template_usage()
RETURNS trigger AS $$
BEGIN
  REFRESH MATERIALIZED VIEW CONCURRENTLY ai_template_usage;
  RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER refresh_template_usage_on_phone_change
  AFTER INSERT OR UPDATE OR DELETE ON signalwire_phone_numbers
  FOR EACH STATEMENT
  EXECUTE FUNCTION refresh_ai_template_usage();

-- Update signalwire_phone_numbers table
ALTER TABLE signalwire_phone_numbers
ADD COLUMN assigned_ai_template_id UUID REFERENCES ai_templates(id) ON DELETE SET NULL;

CREATE INDEX idx_phone_template ON signalwire_phone_numbers(assigned_ai_template_id);

-- RLS Policies
ALTER TABLE ai_templates ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Admins see all templates"
  ON ai_templates FOR SELECT
  USING (auth.jwt() ->> 'role' = 'admin');

CREATE POLICY "Brokers see their own + system defaults"
  ON ai_templates FOR SELECT
  USING (
    broker_id = auth.uid() OR
    is_system_default = TRUE
  );

CREATE POLICY "Brokers create their own templates"
  ON ai_templates FOR INSERT
  WITH CHECK (broker_id = auth.uid() AND is_system_default = FALSE);

CREATE POLICY "Brokers update their own templates"
  ON ai_templates FOR UPDATE
  USING (broker_id = auth.uid() AND is_system_default = FALSE);

CREATE POLICY "Brokers delete unused templates"
  ON ai_templates FOR DELETE
  USING (
    broker_id = auth.uid() AND
    is_system_default = FALSE AND
    NOT EXISTS (
      SELECT 1 FROM signalwire_phone_numbers
      WHERE assigned_ai_template_id = ai_templates.id
    )
  );
```

### Seed System Presets

```sql
INSERT INTO ai_templates (name, description, is_system_default, is_preset, broker_id, 
  stt_provider, stt_model, 
  tts_provider, tts_model, tts_voice_id, 
  llm_provider, llm_model, 
  estimated_cost_per_minute) VALUES

('OpenAI Realtime (Best Quality)', 
  'All-in-one OpenAI solution with GPT-4 Realtime API. Best quality, highest cost.',
  TRUE, TRUE, NULL,
  'openai', 'whisper-1',
  'openai', 'tts-1-hd', 'alloy',
  'openai_realtime', 'gpt-4o-realtime-preview',
  0.45),

('Budget Friendly', 
  'Cost-optimized using Eden AI providers. Good quality at 70% lower cost.',
  TRUE, TRUE, NULL,
  'eden_ai', 'deepgram-nova-2',
  'eden_ai', 'playht-2.0-turbo', 'default',
  'openrouter', 'meta-llama/llama-3.1-70b-instruct',
  0.12),

('Spanish Language', 
  'Optimized for Spanish-speaking leads with multilingual voices.',
  TRUE, TRUE, NULL,
  'eden_ai', 'deepgram-nova-2',
  'eden_ai', 'elevenlabs-multilingual-v2', 'spanish_male',
  'openrouter', 'anthropic/claude-3.5-sonnet',
  0.22);
```

## 2. Backend API (FastAPI)

### File: `livekit-agent/api_server.py`

Add new endpoints:

```python
# ============================================================================
# AI TEMPLATES CRUD
# ============================================================================

@app.get("/api/ai-templates")
async def list_templates(broker_id: Optional[str] = None):
    """List all AI templates (system + broker's custom)"""
    query = supabase.table("ai_templates").select("*, usage:ai_template_usage(phone_count)")
    
    if broker_id:
        query = query.or_(f"broker_id.eq.{broker_id},is_system_default.eq.true")
    else:
        query = query.eq("is_system_default", True)
    
    result = query.order("is_system_default.desc, name.asc").execute()
    return result.data

@app.post("/api/ai-templates")
async def create_template(template: dict):
    """Create new AI template with validation"""
    # Validate provider combinations
    validation_result = await validate_template_config(template)
    if not validation_result["valid"]:
        raise HTTPException(status_code=400, detail=validation_result["errors"])
    
    # Calculate estimated cost
    template["estimated_cost_per_minute"] = calculate_template_cost(template)
    
    result = supabase.table("ai_templates").insert(template).execute()
    return result.data[0]

@app.put("/api/ai-templates/{template_id}")
async def update_template(template_id: str, updates: dict):
    """Update AI template (only if not system default)"""
    # Check if template is system default
    existing = supabase.table("ai_templates").select("*").eq("id", template_id).single().execute()
    if existing.data["is_system_default"]:
        raise HTTPException(status_code=403, detail="Cannot modify system templates")
    
    # Validate updates
    validation_result = await validate_template_config({**existing.data, **updates})
    if not validation_result["valid"]:
        raise HTTPException(status_code=400, detail=validation_result["errors"])
    
    # Recalculate cost
    updates["estimated_cost_per_minute"] = calculate_template_cost({**existing.data, **updates})
    
    result = supabase.table("ai_templates").update(updates).eq("id", template_id).execute()
    return result.data[0]

@app.delete("/api/ai-templates/{template_id}")
async def delete_template(template_id: str):
    """Delete template (only if not in use and not system default)"""
    # Check usage
    usage = supabase.table("signalwire_phone_numbers").select("id").eq("assigned_ai_template_id", template_id).execute()
    if usage.data:
        raise HTTPException(
            status_code=409, 
            detail=f"Template is assigned to {len(usage.data)} phone numbers. Unassign first."
        )
    
    supabase.table("ai_templates").delete().eq("id", template_id).execute()
    return {"success": True}

@app.post("/api/ai-templates/{template_id}/clone")
async def clone_template(template_id: str, broker_id: str, new_name: str):
    """Clone system preset for customization"""
    original = supabase.table("ai_templates").select("*").eq("id", template_id).single().execute()
    
    new_template = {**original.data}
    new_template.pop("id")
    new_template["name"] = new_name
    new_template["broker_id"] = broker_id
    new_template["is_system_default"] = False
    new_template["is_preset"] = False
    
    result = supabase.table("ai_templates").insert(new_template).execute()
    return result.data[0]

# ============================================================================
# VALIDATION & COST CALCULATION
# ============================================================================

async def validate_template_config(template: dict) -> dict:
    """Validate STT/TTS/LLM provider combinations"""
    errors = []
    
    # Check API keys exist
    if template["stt_provider"] == "eden_ai" and not Config.EDENAI_API_KEY:
        errors.append("Eden AI API key not configured")
    if template["llm_provider"] == "openrouter" and not Config.OPENROUTER_API_KEY:
        errors.append("OpenRouter API key not configured")
    if template["llm_provider"] == "openai_realtime" and not Config.OPENAI_API_KEY:
        errors.append("OpenAI API key not configured")
    
    # Check model compatibility (simplified - expand as needed)
    if template["llm_provider"] == "openai_realtime":
        # GPT-realtime requires OpenAI STT/TTS or compatible
        if template["stt_provider"] not in ["openai", "eden_ai"]:
            errors.append("GPT-realtime works best with OpenAI or Eden AI STT")
    
    return {
        "valid": len(errors) == 0,
        "errors": errors
    }

def calculate_template_cost(template: dict) -> float:
    """Estimate $/minute for template configuration"""
    # STT cost (per minute of audio)
    stt_cost = get_stt_cost(template["stt_provider"], template["stt_model"])
    
    # TTS cost (assuming ~150 words/minute, ~25 tokens/sec)
    tts_cost = get_tts_cost(template["tts_provider"], template["tts_model"])
    
    # LLM cost (assuming ~50 tokens/turn, ~4 turns/minute)
    llm_cost = get_llm_cost(template["llm_provider"], template["llm_model"])
    
    return round(stt_cost + tts_cost + llm_cost, 4)

def get_stt_cost(provider: str, model: str) -> float:
    """Get STT cost per minute"""
    pricing = {
        "openai": {"whisper-1": 0.006},
        "deepgram": {"nova-2": 0.0043},
        "assemblyai": {"default": 0.00037},
    }
    # Lookup in Config.PRICING for Eden AI providers
    return pricing.get(provider, {}).get(model, 0.005)

def get_tts_cost(provider: str, model: str) -> float:
    """Get TTS cost per minute (150 words)"""
    pricing = {
        "openai": {"tts-1": 0.015, "tts-1-hd": 0.030},
        "elevenlabs": {"multilingual-v2": 0.180},
        "playht": {"2.0-turbo": 0.040},
    }
    return pricing.get(provider, {}).get(model, 0.020)

def get_llm_cost(provider: str, model: str) -> float:
    """Get LLM cost per minute (200 tokens input + output)"""
    # Use existing Config.PRICING logic
    return Config.get_llm_cost_per_minute(provider, model)

# ============================================================================
# LIVEKIT INTEGRATION
# ============================================================================

@app.post("/api/livekit/test-token")
async def generate_test_token(template_id: str):
    """Generate LiveKit token for testing template in playground"""
    template = supabase.table("ai_templates").select("*").eq("id", template_id).single().execute()
    
    # Create test room
    room_name = f"test-{template_id}-{int(time.time())}"
    token = livekit_api.AccessToken(Config.LIVEKIT_API_KEY, Config.LIVEKIT_API_SECRET)
    token.with_identity(f"tester-{template_id}")
    token.with_name("Test User")
    token.with_grants(VideoGrants(
        room_join=True,
        room=room_name,
        can_publish=True,
        can_subscribe=True
    ))
    
    return {
        "token": token.to_jwt(),
        "room_name": room_name,
        "template": template.data
    }

@app.get("/api/livekit/active-calls")
async def get_active_calls():
    """List all active LiveKit rooms/calls"""
    # Query LiveKit API for active rooms
    rooms = livekit_api.list_rooms(Config.LIVEKIT_API_KEY, Config.LIVEKIT_API_SECRET)
    
    # Enrich with Supabase data
    active_calls = []
    for room in rooms:
        interaction = supabase.table("interactions").select("*").eq("room_name", room.name).single().execute()
        if interaction.data:
            active_calls.append({
                "call_id": room.name,
                "lead_name": interaction.data.get("lead_name"),
                "broker_name": interaction.data.get("broker_name"),
                "duration": int(time.time() - room.creation_time),
                "template_name": interaction.data.get("template_name")
            })
    
    return active_calls

@app.post("/api/livekit/monitor-token/{call_id}")
async def generate_monitor_token(call_id: str):
    """Generate token to monitor an active call (listen-only)"""
    token = livekit_api.AccessToken(Config.LIVEKIT_API_KEY, Config.LIVEKIT_API_SECRET)
    token.with_identity("admin-monitor")
    token.with_name("Admin Monitor")
    token.with_grants(VideoGrants(
        room_join=True,
        room=call_id,
        can_publish=False,  # Listen only
        can_subscribe=True
    ))
    
    return {"token": token.to_jwt()}

# ============================================================================
# PROVIDER DATA (For Dropdown Menus)
# ============================================================================

@app.get("/api/ai-providers/all")
async def get_all_providers():
    """Get complete provider catalog for dropdown population"""
    return {
        "stt_providers": [
            {"id": "eden_ai", "name": "Eden AI (Aggregator)", "description": "Access to Deepgram, AssemblyAI, Google, Whisper, etc."},
            {"id": "openai_realtime", "name": "OpenAI Realtime (Bundled)", "description": "Built-in STT with GPT-4o Realtime"}
        ],
        "tts_providers": [
            {"id": "eden_ai", "name": "Eden AI (Aggregator)", "description": "Access to ElevenLabs, PlayHT, Google, Amazon Polly, etc."},
            {"id": "openai_realtime", "name": "OpenAI Realtime (Bundled)", "description": "Built-in TTS with GPT-4o Realtime"}
        ],
        "llm_providers": [
            {"id": "openrouter", "name": "OpenRouter (Aggregator)", "description": "Access to 100+ LLMs: GPT, Claude, Llama, Gemini, etc."},
            {"id": "openai_realtime", "name": "OpenAI Realtime (Direct)", "description": "GPT-4o Realtime only"}
        ]
    }

@app.get("/api/ai-providers/stt-models")
async def get_stt_models(provider: str):
    """Get available STT models for Eden AI"""
    if provider == "eden_ai":
        return [
            {"id": "deepgram-nova-2", "name": "Deepgram Nova 2", "cost_per_min": 0.0043, "quality": "excellent", "speed": "fast"},
            {"id": "deepgram-base", "name": "Deepgram Base", "cost_per_min": 0.0036, "quality": "good", "speed": "fast"},
            {"id": "assemblyai-best", "name": "AssemblyAI Best", "cost_per_min": 0.00037, "quality": "excellent", "speed": "medium"},
            {"id": "google-latest", "name": "Google Speech Latest", "cost_per_min": 0.006, "quality": "excellent", "speed": "medium"},
            {"id": "whisper-1", "name": "Whisper (via Eden AI)", "cost_per_min": 0.006, "quality": "good", "speed": "slow"},
            {"id": "revai-human-parity", "name": "Rev.ai Human Parity", "cost_per_min": 0.02, "quality": "best", "speed": "slow"}
        ]
    elif provider == "openai_realtime":
        return [
            {"id": "bundled", "name": "Bundled with Realtime", "cost_per_min": 0.0, "quality": "excellent", "speed": "realtime"}
        ]
    return []

@app.get("/api/ai-providers/tts-models")
async def get_tts_models(provider: str):
    """Get available TTS models grouped by underlying provider"""
    if provider == "eden_ai":
        return {
            "grouped_models": [
                {
                    "provider_name": "ElevenLabs",
                    "provider_badge": "premium",
                    "models": [
                        {"id": "elevenlabs-multilingual-v2", "name": "Multilingual V2", "cost_per_min": 0.180, "badge": "best", "languages": 29},
                        {"id": "elevenlabs-turbo-v2.5", "name": "Turbo V2.5", "cost_per_min": 0.090, "badge": "fast", "languages": 32}
                    ]
                },
                {
                    "provider_name": "PlayHT",
                    "provider_badge": "budget",
                    "models": [
                        {"id": "playht-2.0-turbo", "name": "2.0 Turbo", "cost_per_min": 0.040, "badge": "budget", "languages": 20}
                    ]
                },
                {
                    "provider_name": "Google",
                    "provider_badge": "budget",
                    "models": [
                        {"id": "google-neural2", "name": "Neural2", "cost_per_min": 0.024, "badge": "cheapest", "languages": 40}
                    ]
                },
                {
                    "provider_name": "Amazon",
                    "provider_badge": "budget",
                    "models": [
                        {"id": "amazon-polly-neural", "name": "Polly Neural", "cost_per_min": 0.024, "badge": "budget", "languages": 30}
                    ]
                },
                {
                    "provider_name": "OpenAI",
                    "provider_badge": "standard",
                    "models": [
                        {"id": "openai-tts-1", "name": "TTS-1", "cost_per_min": 0.015, "badge": "standard", "languages": 58},
                        {"id": "openai-tts-1-hd", "name": "TTS-1-HD", "cost_per_min": 0.030, "badge": "hd", "languages": 58}
                    ]
                }
            ]
        }
    elif provider == "openai_realtime":
        return {
            "grouped_models": [
                {
                    "provider_name": "OpenAI Realtime",
                    "provider_badge": "bundled",
                    "models": [
                        {"id": "bundled", "name": "Bundled with Realtime", "cost_per_min": 0.0, "badge": "included", "languages": 58}
                    ]
                }
            ]
        }
    return {"grouped_models": []}

@app.get("/api/ai-providers/tts-voices")
async def get_tts_voices(provider: str, model: str):
    """Get available voices for a specific TTS provider/model"""
    # This is a large dataset - in production, consider caching or DB storage
    voices = {
        "eden_ai": {
            "elevenlabs-multilingual-v2": [
                {"id": "21m00Tcm4TlvDq8ikWAM", "name": "Rachel", "gender": "female", "accent": "American", "age": "young", "sample_url": "https://..."},
                {"id": "AZnzlk1XvdvUeBnXmlld", "name": "Domi", "gender": "female", "accent": "American", "age": "young", "sample_url": "https://..."},
                {"id": "EXAVITQu4vr4xnSDxMaL", "name": "Bella", "gender": "female", "accent": "American", "age": "middle", "sample_url": "https://..."},
                {"id": "ErXwobaYiN019PkySvjV", "name": "Antoni", "gender": "male", "accent": "American", "age": "young", "sample_url": "https://..."},
                {"id": "MF3mGyEYCl7XYWbV9V6O", "name": "Elli", "gender": "female", "accent": "American", "age": "young", "sample_url": "https://..."},
                {"id": "TxGEqnHWrfWFTfGW9XjX", "name": "Josh", "gender": "male", "accent": "American", "age": "young", "sample_url": "https://..."},
                {"id": "VR6AewLTigWG4xSOukaG", "name": "Arnold", "gender": "male", "accent": "American", "age": "middle", "sample_url": "https://..."},
                {"id": "pNInz6obpgDQGcFmaJgB", "name": "Adam", "gender": "male", "accent": "American", "age": "middle", "sample_url": "https://..."},
                {"id": "yoZ06aMxZJJ28mfd3POQ", "name": "Sam", "gender": "male", "accent": "American", "age": "young", "sample_url": "https://..."},
            ],
            "playht-2.0-turbo": [
                {"id": "s3://voice-cloning-zero-shot/d9ff78ba-d016-47f6-b0ef-dd630f59414e/female-cs/manifest.json", "name": "Charlotte (Female)", "gender": "female", "accent": "American"},
                {"id": "s3://voice-cloning-zero-shot/d82d246c-148b-457f-9668-37b789520891/original/manifest.json", "name": "Ethan (Male)", "gender": "male", "accent": "American"},
                # Add more PlayHT voices
            ],
            "google-neural2": [
                {"id": "en-US-Neural2-A", "name": "US Neural2 A (Male)", "gender": "male", "accent": "American"},
                {"id": "en-US-Neural2-C", "name": "US Neural2 C (Female)", "gender": "female", "accent": "American"},
                {"id": "en-US-Neural2-D", "name": "US Neural2 D (Male)", "gender": "male", "accent": "American"},
                {"id": "en-US-Neural2-E", "name": "US Neural2 E (Female)", "gender": "female", "accent": "American"},
                {"id": "en-US-Neural2-F", "name": "US Neural2 F (Female)", "gender": "female", "accent": "American"},
            ],
            "openai-tts-1": [
                {"id": "alloy", "name": "Alloy (Neutral)", "gender": "neutral", "accent": "American"},
                {"id": "echo", "name": "Echo (Male)", "gender": "male", "accent": "American"},
                {"id": "fable", "name": "Fable (Female)", "gender": "female", "accent": "British"},
                {"id": "onyx", "name": "Onyx (Male)", "gender": "male", "accent": "American"},
                {"id": "nova", "name": "Nova (Female)", "gender": "female", "accent": "American"},
                {"id": "shimmer", "name": "Shimmer (Female)", "gender": "female", "accent": "American"},
            ]
        },
        "openai_realtime": {
            "bundled": [
                {"id": "alloy", "name": "Alloy (Neutral)", "gender": "neutral", "accent": "American"},
                {"id": "echo", "name": "Echo (Male)", "gender": "male", "accent": "American"},
                {"id": "shimmer", "name": "Shimmer (Female)", "gender": "female", "accent": "American"},
            ]
        }
    }
    return voices.get(provider, {}).get(model, [])

@app.get("/api/ai-providers/llm-models")
async def get_llm_models(provider: str):
    """Get available LLM models"""
    if provider == "openrouter":
        # Fetch live from OpenRouter API (cached for 1 hour)
        # For now, return curated list of popular models
        return [
            # OpenAI Models
            {"id": "openai/gpt-4o", "name": "GPT-4 Omni", "provider": "OpenAI", "context": 128000, "cost_per_1m_tokens": 5.0, "speed": "fast"},
            {"id": "openai/gpt-4o-mini", "name": "GPT-4 Omni Mini", "provider": "OpenAI", "context": 128000, "cost_per_1m_tokens": 0.15, "speed": "very_fast"},
            {"id": "openai/gpt-4-turbo", "name": "GPT-4 Turbo", "provider": "OpenAI", "context": 128000, "cost_per_1m_tokens": 10.0, "speed": "medium"},
            
            # Anthropic Models
            {"id": "anthropic/claude-3.5-sonnet", "name": "Claude 3.5 Sonnet", "provider": "Anthropic", "context": 200000, "cost_per_1m_tokens": 3.0, "speed": "fast"},
            {"id": "anthropic/claude-3-opus", "name": "Claude 3 Opus", "provider": "Anthropic", "context": 200000, "cost_per_1m_tokens": 15.0, "speed": "medium"},
            {"id": "anthropic/claude-3-haiku", "name": "Claude 3 Haiku", "provider": "Anthropic", "context": 200000, "cost_per_1m_tokens": 0.25, "speed": "very_fast"},
            
            # Meta Models
            {"id": "meta-llama/llama-3.1-70b-instruct", "name": "Llama 3.1 70B", "provider": "Meta", "context": 128000, "cost_per_1m_tokens": 0.88, "speed": "fast"},
            {"id": "meta-llama/llama-3.1-8b-instruct", "name": "Llama 3.1 8B", "provider": "Meta", "context": 128000, "cost_per_1m_tokens": 0.07, "speed": "very_fast"},
            
            # Google Models
            {"id": "google/gemini-pro-1.5", "name": "Gemini 1.5 Pro", "provider": "Google", "context": 1000000, "cost_per_1m_tokens": 3.5, "speed": "medium"},
            {"id": "google/gemini-flash-1.5", "name": "Gemini 1.5 Flash", "provider": "Google", "context": 1000000, "cost_per_1m_tokens": 0.075, "speed": "very_fast"},
            
            # Mistral Models
            {"id": "mistralai/mistral-large", "name": "Mistral Large", "provider": "Mistral", "context": 128000, "cost_per_1m_tokens": 4.0, "speed": "fast"},
            {"id": "mistralai/mistral-small", "name": "Mistral Small", "provider": "Mistral", "context": 32000, "cost_per_1m_tokens": 0.2, "speed": "very_fast"},
        ]
    elif provider == "openai_realtime":
        return [
            {"id": "gpt-4o-realtime-preview", "name": "GPT-4 Omni Realtime", "provider": "OpenAI", "context": 128000, "cost_per_1m_tokens": 10.0, "speed": "realtime"}
        ]
    return []
```

## 3. GPT-Realtime Prompt Conversion

### File: `livekit-agent/services/prompt_adapter.py` (NEW)

```python
"""
Prompt Adapter for GPT-Realtime API
Converts structured prompts to OpenAI Realtime format
Based on barbara-v3 conversion layer
"""

def convert_prompt_for_realtime(prompt_content: dict, variables: dict) -> str:
    """
    Convert structured prompt to GPT-realtime format
    
    GPT-realtime requires:
    - Single 'instructions' field (not messages array)
    - Straightline structure with clear sections
    - Bullet points over paragraphs
    - No {{user_question}} placeholder
    """
    parts = []
    
    # 1. Core role (non-negotiable, first)
    if prompt_content.get("role"):
        parts.append(prompt_content["role"].strip())
    else:
        parts.append(
            "You are Barbara, a warm, professional voice assistant for Equity Connect. "
            "You help seniors understand reverse mortgage options, verify their information, "
            "answer questions accurately, and schedule time with their assigned broker."
        )
    
    # 2. Personality & style (critical for voice behavior)
    if prompt_content.get("personality"):
        parts.append(f"PERSONALITY & STYLE:\n{prompt_content['personality'].strip()}")
    else:
        parts.append(
            "PERSONALITY & STYLE:\n"
            "- Warm, calm, patient, never pushy.\n"
            "- Short turns (1–2 concise sentences).\n"
            "- Stop speaking immediately if the caller starts talking.\n"
            "- Use the caller's first name only in the greeting, not repeatedly."
        )
    
    # 3. Realtime-specific behavior (hardcoded runtime rules)
    parts.append(
        "REALTIME BEHAVIOR (OPENAI REALTIME SPECIFIC):\n"
        "- Stop talking immediately if the caller interrupts you.\n"
        "- If there is about 2 seconds of silence, use a soft filler (\"mm-hmm\", \"okay\").\n"
        "- If there is about 5 seconds of silence, gently prompt (\"Whenever you're ready\").\n"
        "- While tools run, briefly narrate once (\"Let me check that for you\").\n"
        "- Speak in natural, concise sentences suited for seniors.\n"
        "- Express all important numbers as words (\"sixty-two\", \"five hundred thousand\").\n"
        "- Do not read bullet points or labels out loud verbatim; respond conversationally."
    )
    
    # 4. Context (with variable injection)
    if prompt_content.get("context"):
        context = inject_variables(prompt_content["context"], variables)
        parts.append(f"CONTEXT:\n{context}")
    
    # 5. Tools (conceptual usage only)
    if prompt_content.get("tools"):
        parts.append(f"TOOLS (HOW TO USE THEM):\n{prompt_content['tools'].strip()}")
    
    # 6. Conversation flow
    if prompt_content.get("conversation_flow"):
        parts.append(f"CONVERSATION FLOW:\n{prompt_content['conversation_flow'].strip()}")
    
    # 7. Rules & constraints
    if prompt_content.get("instructions"):
        parts.append(f"RULES & CONSTRAINTS:\n{prompt_content['instructions'].strip()}")
    
    # 8. Safety & escalation
    if prompt_content.get("safety"):
        parts.append(f"SAFETY & ESCALATION:\n{prompt_content['safety'].strip()}")
    
    # 9. Output format
    if prompt_content.get("output_format"):
        parts.append(f"OUTPUT FORMAT:\n{prompt_content['output_format'].strip()}")
    else:
        parts.append(
            "OUTPUT FORMAT:\n"
            "- Natural spoken language only.\n"
            "- 1–2 sentences per turn unless more detail is requested.\n"
            "- Use words instead of numerals for key numbers and dollar amounts.\n"
            "- Do not read internal labels (like CONTEXT, TOOLS) aloud."
        )
    
    # 10. Pronunciation guide
    if prompt_content.get("pronunciation"):
        parts.append(f"PRONUNCIATION:\n{prompt_content['pronunciation'].strip()}")
    else:
        parts.append(
            "PRONUNCIATION:\n"
            "- \"NMLS\" → say \"N-M-L-S\".\n"
            "- \"Equity\" → say \"EH-kwi-tee\"."
        )
    
    return "\n\n".join(parts).strip()

def inject_variables(text: str, variables: dict) -> str:
    """Inject variables into prompt text"""
    # Remove {{user_question}} placeholder (used for chat completion, not realtime)
    enriched_variables = {
        **variables,
        "user_question": "",  # Remove this placeholder
        "user": variables.get("user") or variables.get("leadFirstName", ""),
        "context": variables.get("context") or variables.get("callContext", "inbound")
    }
    
    result = text
    for key, value in enriched_variables.items():
        result = result.replace(f"{{{{{key}}}}}", str(value))
    
    return result
```

### Update `livekit-agent/agent.py` to use adapter:

```python
from services.prompt_adapter import convert_prompt_for_realtime

# In entrypoint function, when loading prompt:
if llm_provider == "openai_realtime":
    # Load prompt from Supabase
    prompt_data = get_prompt_for_phone(phone_number)
    
    # Convert to GPT-realtime format
    realtime_instructions = convert_prompt_for_realtime(
        prompt_content=prompt_data["content"],
        variables={
            "leadFirstName": lead_info.get("first_name"),
            "brokerName": broker_info.get("contact_name"),
            "callContext": "inbound",  # or "outbound"
            # ... all 27 variables
        }
    )
    
    # Use converted prompt
    llm_instance = openai.RealtimeModel(
        api_key=Config.OPENAI_API_KEY,
        instructions=realtime_instructions
    )
```

## 4. Vue Frontend Components

### Component 1: `portal/src/components/AITemplatesManager.vue`

Lists templates with usage counts, clone/edit/delete actions.

### Component 2: `portal/src/components/AITemplateForm.vue`

Two-mode form (Preset + Advanced) with:

- Real-time cost calculation display
- Validation feedback (red/green indicators)
- Voice preview player (play 5-second TTS sample)
- "Test in Playground" button

### Component 3: `portal/src/views/admin/LiveKitPlayground.vue`

Iframe wrapper + native LiveKit components option.

### Component 4: `portal/src/views/admin/LiveCalls.vue`

Active calls table with monitor button.

### Update: `portal/src/views/admin/BrokerDetail.vue`

Add new tab:

```vue
<n-tab-pane name="ai-templates" tab="AI Templates">
  <AITemplatesManager :broker-id="brokerId" />
</n-tab-pane>
```

## 5. Integration with Prompts System

- **Template → Prompt Link**: Each phone number has BOTH `assigned_ai_template_id` AND `prompt_id`
- **Loading Logic**: Agent loads template for provider config, loads prompt for content
- **Realtime Conversion**: If template uses `openai_realtime`, prompt is converted via `prompt_adapter.py`

## 6. Fallback Logic

```python
async def get_agent_config_with_fallback(phone_number: str):
    """Get agent config with fallback chain"""
    # 1. Try phone's assigned template
    template = get_template_for_phone(phone_number)
    
    if not template:
        # 2. Fallback to broker's default template
        broker_id = get_broker_for_phone(phone_number)
        template = get_default_template_for_broker(broker_id)
    
    if not template:
        # 3. Fallback to system default (OpenAI Realtime)
        template = get_system_default_template()
    
    # Validate providers are available
    if not validate_providers_available(template):
        # 4. Emergency fallback to Budget template
        template = get_template_by_name("Budget Friendly")
    
    return template
```

## 7. NPM Dependencies

Add to `portal/package.json`:

```json
{
  "dependencies": {
    "@blockgain/livekit-vue": "^1.0.0",
    "livekit-client": "^2.0.0"
  }
}
```

## 8. Documentation

Create `livekit-agent/docs/AI_TEMPLATES_GUIDE.md` with:

- Provider rate limits
- Voice ID reference table
- Model compatibility matrix
- Cost breakdown by provider
- Best practices for template configuration